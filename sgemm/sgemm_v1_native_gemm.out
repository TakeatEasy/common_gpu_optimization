#include <iostream>
#include <stdio.h>
#include <stdlib.h>

#include <cuda_runtime.h>

#include "util/utils.hpp"

#define ASIZE(type) (sizeof(type) * M * K)
#define BSIZE(type) (sizeof(type) * K * N)
#define CSIZE(type) (sizeof(type) * M * N)

#define BLOCK_SIZE                                                             \
  16 // we assume that every block has equal blockDim.x and blockDim.y

__global__ void sgemm(const float *A, const float *B, float *C, int M, int N,
                      int K, float alpha, float beta) {

  const int tx = blockIdx.x * blockDim.x + threadIdx.x;
  const int ty = blockIdx.y * blockDim.y + threadIdx.y;

  float c = 0;
  if (tx < M && ty < N) {
    for (int i = 0; i < K; i++) {
      c += A[tx * K + i] * B[ty + i * N];
    }
    C[tx * N + ty] = beta * C[tx * N + ty] + alpha * c;
  }
}

void matrixMul(int M, int N, int K, float *a, float *b, float *c,
               float alpha = 1, float beta = 0) {
  dim3 threadsPerBlock(BLOCK_SIZE, BLOCK_SIZE);
  dim3 numBlocks((M + threadsPerBlock.x - 1) / (threadsPerBlock.x),
                 (N + threadsPerBlock.y - 1) / (threadsPerBlock.y));
  sgemm<<<numBlocks, threadsPerBlock>>>(a, b, c, M, N, K, alpha, beta);
}


int main(int argc, char **argv) {
  size_t M = 1024;
  size_t N = 1024;
  size_t K = 1024;

  std::cout << M << " " << N << " " << K << std::endl;

  float *h_A = new float[M * K];
  float *h_B = new float[N * K];
  float *h_C = new float[M * N];
  float *h_C1 = new float[M * N];

  float *d_A;
  float *d_B;
  float *d_C;

  checkCudaErrors(cudaMalloc(&d_A, ASIZE(float)));
  checkCudaErrors(cudaMalloc(&d_B, ASIZE(float)));
  checkCudaErrors(cudaMalloc(&d_C, ASIZE(float)));

  const int BLOCK_SIZE_M = 96;
  const int BLOCK_SIZE_K = 32;
  const int BLOCK_SIZE_N = 64;
  const int THREAD_SIZE_Y = 6;
  const int THREAD_SIZE_X = 4;
  const bool ENABLE_DOUBLE_BUFFER = false;
  const float alpha = 2;
  const float beta = 2;

  genRandomMatrix(h_A, M, K);
  genRandomMatrix(h_B, K, N);
  genRandomMatrix(h_C, M, N);
  copyMatrix(h_C1, h_C, M, N);

  checkCudaErrors(cudaMemcpy(d_A, h_A, ASIZE(float), cudaMemcpyHostToDevice));
  checkCudaErrors(cudaMemcpy(d_B, h_B, ASIZE(float), cudaMemcpyHostToDevice));
  checkCudaErrors(cudaMemcpy(d_C, h_C, ASIZE(float), cudaMemcpyHostToDevice));

  // for evaluation
  for (int i = 0; i < M; i++) {
    for (int j = 0; j < N; j++) {
      h_C[i * N + j] = beta * h_C[i * N + j];
      for (int k = 0; k < K; k++)
        h_C[i * N + j] += alpha * h_A[i * K + k] * h_B[k * N + j];
    }
  }

  cudaEvent_t start, stop;
  checkCudaErrors(cudaEventCreate(&start));
  checkCudaErrors(cudaEventCreate(&stop));
  float msecTotal = 0;
  int nIter = 100;

  matrixMul(M, N, K, d_A, d_B, d_C, alpha, beta);

  checkCudaErrors(cudaMemcpy(h_C, d_C, CSIZE(float), cudaMemcpyDeviceToHost));

  checkCudaErrors(cudaFree(d_A));
  checkCudaErrors(cudaFree(d_B));
  checkCudaErrors(cudaFree(d_C));

  delete[] h_A;
  printf("Ok A\n");
  delete[] h_B;
  printf("Ok B\n");
  delete[] h_C;
  printf("Ok C\n");
  delete[] h_C1;
  printf("Ok C1\n");
}